# ğŸ¤–â¿âš™ Website Verticalizer
Productionâ€‘grade system to classify websites into IAB categories and generate geoâ€‘specific Premiumness Scores (1â€“10).

See also
- docs/website_verticalizer_spec.md â€” for an oveerview of the project.
- docs/website_verticalizer_deep_dive.md - for deep dive into Website Verticalizer
- docs/premiumness_scoring_spec.md - for deep dive into Premiumness Scoring
- CONTRIBUTING.md â€” contributor workflow and QA gates.

***

## ğŸ“Œ Overview
Website Verticalizer is a modular ML pipeline that:
- Performs multilabel IAB Tierâ€‘1 classification (Tierâ€‘2 optional as label coverage grows).
- Assigns geoâ€‘specific Premiumness Scores (1â€“10) per category when labels are available.
- Operates on labeled or unlabeled inputs via crawl â†’ embed â†’ train â†’ infer â†’ eval stages.
- Combines crawled content, semantic embeddings, a twoâ€‘head Keras model, and perâ€‘label calibration.

Built for reproducibility, caching, cost controls, and perâ€‘geo artifact versioning.

***

## ğŸš€ Features
- Multiâ€‘label IAB classification with Keras on semantic embeddings.
- Pluggable embedder with cacheâ€‘first behavior, rate limiting, retries, dryâ€‘run, and maxâ€‘calls; Gemini client is implemented; other providers can be added via the same interface.
- Robots.txtâ€‘aware crawler with readability extraction; Postgres metadata; optional object storage for raw HTML and vectors.
- Premiumness Score head per vertical, clamped to 1â€“10 and normalized during training.
- Perâ€‘label isotonic probability calibration (applied at inference on classification head only).
- Decoupled CLIs: crawl, embed, train, infer, eval; plus runâ€‘pipeline orchestrator.
- Fileâ€‘driven I/O; structured logging; idempotent reruns.

Note: The codebase ships a Gemini embedder; if another provider is desired, add a provider client matching the Gemini interface.

***

## ğŸ— Architecture & Workflow
Highâ€‘level flow; see docs/spec.md for the detailed diagrams.
- Inputs (CSV/Excel: websites, labels) â†’ Crawl (robotsâ€‘aware) â†’ Embed (cache, dedup, batch) â†’ Train (twoâ€‘head Keras, perâ€‘label isotonic) â†’ Artifacts (model.keras, calib.pkl) â†’ Infer (predict probs+scores; apply calibration) â†’ Output JSONL.
- Calibration applies to probabilities only; scores are discretized 1..10 at inference.

Mermaid diagram is in the spec to avoid duplication.

***

## ğŸ“‚ Project Structure
```
repo/
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ spec.md
â”œâ”€â”€ CONTRIBUTING.md
â”œâ”€â”€ .env.example
â”œâ”€â”€ src/
â”‚   â””â”€â”€ verticalizer/
â”‚      â”œâ”€â”€ cli.py
â”‚      â”œâ”€â”€ apps/{crawler,embedder,trainer,infer,evaluate}/
â”‚      â”œâ”€â”€ crawl/        # fetcher, parse, robots
â”‚      â”œâ”€â”€ embeddings/   # provider clients + cache (Gemini implemented)
â”‚      â”œâ”€â”€ models/       # Keras, calibration, persistence, registry
â”‚      â”œâ”€â”€ pipeline/     # common helpers, nodes, io
â”‚      â”œâ”€â”€ storage/      # Postgres & S3 clients and repositories
â”‚      â””â”€â”€ utils/        # logging, taxonomy, metrics, seed
â””â”€â”€ tests/
```


***

## ğŸ“Š Data Contracts
Pointers only; full contracts live in docs/spec.md.

- Labeled CSV: website, iablabels (JSON/CSV), premiumnesslabels (IABâ†’1..10), optional contenttext, optional geo; IDs normalized to uppercase IAB codes.
- Unlabeled CSV: website with optional contenttext; supports inference or classificationâ€‘only training.
- Predictions JSONL: {website, geo, categories[{id,label,prob,score}], generated_at}; model selection via path or registry.

Example rows and Excelâ†’CSV/JSON converter are documented in the spec and CLI help.

***

## âš™ï¸ Installation
Prerequisites: Python 3.10+, Poetry; Postgres recommended; S3/minio optional for blobs.

Setup
```
poetry install
cp .env.example .env
```
Core env keys (full list in docs/spec.md):
- GEMINI_API_KEY, GEMINI_EMB_MODEL, GEMINI_EMB_DIM, GEMINI_TASK_TYPE, GEMINI_EMB_DRYRUN, GEMINI_EMB_MAX_CALLS, GEMINI_EMB_RATE_LIMIT.
- DATABASE_URL (Postgres DSN), S3 credentials, HTTP_USER_AGENT/HTTPTIMEOUT for crawler.

Provider note: The runtime embedder is Gemini by default; additional providers require adding a client under embeddings/ with the same caching and rateâ€‘limit hooks.

***

## ğŸ“œ Commands
Topâ€‘level entrypoint:
```
poetry run verticalizer [command] [options]
```
- Crawl: robotsâ€‘aware fetch and persistence.
- Embed: embed latest text with cache and cost controls.
- Train: fit twoâ€‘head Keras and save calibrator; records artifacts per geo/version.
- Infer: prepare embeddings, predict, apply calibrator (probs only), write JSONL.
- Eval: compare predictions vs gold; emits JSON report.
- Run pipeline: Excelâ†’CSV/JSONâ†’trainâ†’inferâ†’compare orchestration.

CLI switches and examples are in the spec to avoid duplication.

***

## ğŸ“ˆ Ops & Quality Tips
- Keep taxonomy JSONs consistent across stages; pin seeds for reproducibility.
- Maximize embedding cache hits; use QPS and maxâ€‘calls to meet budget; DRYRUN for smoke tests.
- Monitor zeroâ€‘vector share, stale embeddings vs lasthash, and crawl errors in logs.

***

## ğŸ”’ Compliance
- robots.txt respected; courtesy delay and configurable UA/timeout.
- No PII; secrets via env; idempotent reruns with durable storage for audits.

***

## ğŸ§ª Testing
```
poetry run pytest
```
Linting and style:
```
poetry run ruff check src --fix
```
For PR process and QA gates, see CONTRIBUTING.md.

***

## ğŸ“š Specification
For scope, requirements, persistence contracts, acceptance gates, diagrams, and roadmap, see docs/spec.md.

***

## ğŸ§­ Troubleshooting
- Gemini key or permission errors: set GEMINI_API_KEY; disable GEMINI_EMB_DRYRUN for real vectors.
- Robots denial: provide contenttext in CSV to bypass crawl; then run embed/infer.
- Empty vectors during dryâ€‘run/maxâ€‘calls: expected zeroâ€‘vectors; lower restrictions for production runs.

***

## ğŸ· License
Proprietary â€” internal use only.

***